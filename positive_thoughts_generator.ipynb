{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Thoughts Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenIA library and file containing the OpenAI access key\n",
    "import openai\n",
    "import credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set OpenAI API key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OpenAI API key by assigning the value from credentials.openai_key to openai.api_key. \n",
    "# This step ensures that the API key is properly configured for making API requests.  \n",
    "\n",
    "openai.api_key = credentials.openai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Generate a Positive Thought from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a positive thought using OpenAI\n",
    "# The function named generate_positive_thought takes two parameters: system_message and user_prompt.\n",
    "def generate_positive_thought(system_prompt, user_prompt):\n",
    "# Define a list called messages that contains two dictionaries representing the system and user messages/prompts.\n",
    "    messages_list = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    # Make a call to the OpenAI API using openai.ChatCompletion.create. The response from the API call is stored in the response variable.\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages_list, \n",
    "        max_tokens=100,  # Adjusting this value allows you to control the length of the generated response\n",
    "        temperature=0.5  # A higher value, such as 0.8, makes the output more random and diverse. A lower value of 0.2 makes the output more focused.\n",
    "    )\n",
    "    \n",
    "    positive_thought = response.choices[0].message.content.strip() # extracts the generated positive thought from the response\n",
    "    return positive_thought\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an expert in generating positive thoughts.\"  # system-level instruction or prompt\n",
    "user_prompt = \"I am grateful for the little things in life that bring me joy and happiness tell me a positive thought\" # user interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Generate Positive Thought Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Thought:  Every day is filled with countless opportunities to find joy and happiness in the little things. Whether it's savoring a warm cup of coffee, feeling the sun on your face, or sharing a laugh with a loved one, these small moments are what make life truly beautiful and meaningful. Embrace them, appreciate them, and let them fill your heart with gratitude and happiness.\n"
     ]
    }
   ],
   "source": [
    "response = generate_positive_thought(system_prompt, user_prompt)\n",
    "print(\"Positive Thought: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other parameters used for tweaking the response from OpenAI API \n",
    "\n",
    "In addition to the max_tokens and temperature parameters, there are a few other parameters you can use to tweak the responses from the OpenAI API. These parameters include:\n",
    "\n",
    "**n**: This parameter controls the number of responses to generate. By default, it is set to 1, but you can increase it to generate multiple alternative completions. \n",
    "\n",
    "**stop**: You can provide a list of strings in the stop parameter to specify phrases or tokens at which you want the model to stop generating the response. This can be useful if you want to ensure the response doesn't go beyond a certain point or to prevent certain types of content. \n",
    "\n",
    "**presence_penalty**: This parameter affects the model's behavior regarding repeating or reusing certain phrases. A higher value, such as 0.6, makes the model less likely to repeat phrases. A lower value, such as 0.2, allows for more repetition. \n",
    "\n",
    "**frequency_penalty**: This parameter controls how much the model balances between sticking to the prompt and exploring new possibilities. A higher value, like 0.8, makes the model more focused and likely to generate responses similar to the input prompt. A lower value, like 0.2, makes the model more creative and likely to explore diverse responses. \n",
    "\n",
    "By adjusting these parameters, you can fine-tune the behavior of the model and the generated responses to better fit your needs. Keep in mind that experimentation and testing different combinations of these parameters can help you achieve the desired results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
